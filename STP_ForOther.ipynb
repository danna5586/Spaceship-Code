{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "kWXfqhFeIjbL",
        "outputId": "61b8c835-591b-48f1-974b-03996bd52ad1"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'train.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c880ec4a5417>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# data adalah csv train.csv yang digunakan untuk training, dengan syarat train.csv di download dulu dari kaggle Spaceship Titanic Problem dan dimasukkan ke folder yang sama dengan file ini\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# test adalah data test yang digunakan untuk membuat output berupa csv untuk disubmit, dengan syarat test.csv di download dulu dari kaggle Spaceship Titanic Problem dan dimasukkan ke folder yang sama dengan file ini\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
          ]
        }
      ],
      "source": [
        "# Import library yang dibutuhkan\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Models adalah kumpulan class yang digunakan untuk data training, berbentuk 2D array\n",
        "models = [[GaussianNB(), 'GNB'],\n",
        "          [KNeighborsClassifier(), 'KNN'],\n",
        "          [SVC(), 'SVM'],\n",
        "          [DecisionTreeClassifier(), 'Decision Tree']]\n",
        "\n",
        "# data adalah csv train.csv yang digunakan untuk training, dengan syarat train.csv di download dulu dari kaggle Spaceship Titanic Problem dan dimasukkan ke folder yang sama dengan file ini\n",
        "data = pd.read_csv('train.csv')\n",
        "\n",
        "# test adalah data test yang digunakan untuk membuat output berupa csv untuk disubmit, dengan syarat test.csv di download dulu dari kaggle Spaceship Titanic Problem dan dimasukkan ke folder yang sama dengan file ini\n",
        "test = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33wAjaD4IjbN"
      },
      "outputs": [],
      "source": [
        "# Melihat informasi data\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5ulT350IjbO"
      },
      "outputs": [],
      "source": [
        "# Melihat informasi data 2\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsfKMcHOIjbO"
      },
      "outputs": [],
      "source": [
        "# Fitur yang digunakan adalah berupa array, digunakan untuk menyeleksi fitur yang relevan untuk prediksi\n",
        "fitur_yang_digunakan = ['HomePlanet', 'CryoSleep', 'VIP', 'Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
        "\n",
        "# Target adalah data yang ingin diprediksi\n",
        "target = ['Transported']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3hKcDUtIjbP"
      },
      "outputs": [],
      "source": [
        "# Imputer digunakan untuk mengisi value yang bersifat NaN atau kosong, agar data bisa di train\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Proses imputasi data dari NaN ke data yang sering muncul di fitur tersebut\n",
        "data.iloc[:, :-1] = imputer.fit_transform(data.iloc[:, :-1])\n",
        "test.iloc[:, :] = imputer.transform(test.iloc[:, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jVZooVMIjbP"
      },
      "outputs": [],
      "source": [
        "# Proses seleksi fitur yang dipakai, dari yang lengkap, menjadi fitur-fitur yang relevan saja yang dipakai\n",
        "data = data[fitur_yang_digunakan + target]\n",
        "test = test[fitur_yang_digunakan]\n",
        "\n",
        "# Untuk mengetahui jumlah fitur yang terlibat, bisa print n untuk mengetahui jumlah fitur yang dipakai\n",
        "fitur = data.drop(columns=target)\n",
        "n = fitur.shape[1]\n",
        "\n",
        "# print(n)\n",
        "\n",
        "# Mulai memisahkan antara fitur dengan target\n",
        "arr = data.values\n",
        "X = arr[:,0:n]\n",
        "y = arr[:,n]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOjvuaYeIjbP"
      },
      "outputs": [],
      "source": [
        "# Label encoder digunakan untuk mengubah data berupa kategori menjadi numerik, misal data berupa low, medium, high akan diganti dengan angka misal 0, 1, 2 agar dapat di train\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Untuk setiap kolom yang berupa kategori, dibuat menjadi bentuk numerik\n",
        "for kolom in fitur.select_dtypes(include='object'):\n",
        "  fitur[kolom] = encoder.fit_transform(fitur[kolom])\n",
        "  test[kolom] = encoder.transform(test[kolom])\n",
        "\n",
        "# Dimasukkan dalam variabel X dan X_test, X untuk data training, dan X_test untuk data lengkapnya\n",
        "X = fitur.values\n",
        "X_test = test.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epqg6PO6IjbP"
      },
      "outputs": [],
      "source": [
        "# Mengecek apakah X sudah berupa numerik semua\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWY2JyhJIjbQ"
      },
      "outputs": [],
      "source": [
        "# Mengecek apakah X_test sudah berupa numerik semua\n",
        "X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WAq90S6IjbQ"
      },
      "outputs": [],
      "source": [
        "# Mengecek bentuk dari kolom target yaitu y\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHkJoNejIjbQ"
      },
      "outputs": [],
      "source": [
        "# Mengubah bentuk y menjadi numerik agar dapat mengambil classification reportnya\n",
        "y = np.array(y, dtype=int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGgAhJjnIjbQ"
      },
      "outputs": [],
      "source": [
        "# Mengecek jika y sudah berbentuk numerik\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMsIfs5MIjbR"
      },
      "outputs": [],
      "source": [
        "# X dan y diambil dari data training, sehingga kita membuat data test sendiri untuk proses training, atau yang disebut dengan X_validation dan y_validation menggunakan library sklearn.model_selection train_test_split\n",
        "# test_size 0.2 berarti 80% data merupakan X_train dan y_train, 20% data merupakan X_validation dan y_validation\n",
        "# random_state hanya agar train_test_split bersifat konsisten atau tidak berubah-ubah, bisa diisi nilai bilangan bulat terserah\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2, random_state=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIemCqjUIjbR"
      },
      "outputs": [],
      "source": [
        "# Fungsi ini diambil dari modul 8 Praktikum\n",
        "results = []\n",
        "\n",
        "for model in models:\n",
        "    kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
        "    cv_results = cross_val_score(model[0], X_train, y_train, cv=kfold, scoring='accuracy')\n",
        "    results.append(cv_results)\n",
        "    print('%s: %f (%f)' % (model[1], cv_results.mean(), cv_results.std()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFM_u_iPIjbR"
      },
      "source": [
        "# Karena SVM adalah model yang memiliki akurasi paling tinggi, maka kita akan menggunakan SVM untuk data training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYFiCkFfIjbS"
      },
      "outputs": [],
      "source": [
        "# Verifikasi ulang data, apakah data berubah, seharusnya data tidak berubah karena hanya mengambil value dari data (variabel arr di cell 23)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kzhhTtXIjbS"
      },
      "outputs": [],
      "source": [
        "# Proses training data menggunakan model terbaik, memanggil fungsi fit\n",
        "models[2][0].fit(X, y)\n",
        "\n",
        "# Prediksi data dari data train 20%\n",
        "prediksi = models[2][0].predict(X_validation)\n",
        "\n",
        "# Print report klasifikasi\n",
        "print(\"Report klasifikasi untuk model terbaik yaitu SVM: \")\n",
        "print(classification_report(y_validation, prediksi))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vJ3tadlIjbS"
      },
      "outputs": [],
      "source": [
        "# Prediksi data dari data test dari test.csv yang bentuknya sudah diubah agar dapat diprediksi berdasarkan data training\n",
        "prediksi = models[2][0].predict(X_test)\n",
        "\n",
        "# Karena prediksi berupa angka, harus diubah kembali dalam bentuk True dan False\n",
        "label = {0: \"False\", 1: \"True\"}\n",
        "prediksi_text = [label[val] for val in prediksi]\n",
        "\n",
        "# Mengambil PassengerId dari test.csv, karena test.csv sebelumnya sudah ditransform agar bisa diprediksi\n",
        "id_penumpang = pd.read_csv('test.csv')['PassengerId']\n",
        "\n",
        "# Membuat panda dataframe dari PassengerId dan hasil prediksi yang sudah dibuat\n",
        "output_df = pd.DataFrame({'PassengerId': id_penumpang, 'Transported': prediksi_text})\n",
        "\n",
        "# Output csv, kalau di run harusnya keluar prediksi.csv didalam folder, submit file tersebut ke kaggle Spaceship Titanic Problem\n",
        "output_df.to_csv(\"prediksi.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
